{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# D√©tection de Fraude - Experiment Tracking avec Plusieurs Mod√®les\n",
        "## Azure ML + MLflow - Comparaison de Versions\n",
        "\n",
        "**Objectif**: Entra√Æner et comparer plusieurs versions de mod√®les de d√©tection de fraude\n",
        "\n",
        "**Mod√®les test√©s**:\n",
        "1. Random Forest (baseline)\n",
        "2. Random Forest (optimis√©)\n",
        "3. XGBoost\n",
        "4. LightGBM\n",
        "\n",
        "---"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Configuration et Imports"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pandas numpy scikit-learn imbalanced-learn matplotlib seaborn mlflow joblib xgboost lightgbm azureml-core\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Requirement already satisfied: pandas in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (2.3.1)\nRequirement already satisfied: numpy in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (2.2.6)\nRequirement already satisfied: scikit-learn in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (1.7.2)\nRequirement already satisfied: imbalanced-learn in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (0.14.1)\nRequirement already satisfied: matplotlib in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (3.10.8)\nRequirement already satisfied: seaborn in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (0.13.2)\nRequirement already satisfied: mlflow in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (3.8.1)\nRequirement already satisfied: joblib in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (1.5.3)\nRequirement already satisfied: xgboost in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (3.1.2)\nRequirement already satisfied: lightgbm in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (4.6.0)\nRequirement already satisfied: azureml-core in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (1.60.0.post1)\nRequirement already satisfied: python-dateutil>=2.8.2 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from pandas) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from pandas) (2025.2)\nRequirement already satisfied: scipy>=1.8.0 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from scikit-learn) (1.15.3)\nRequirement already satisfied: threadpoolctl>=3.1.0 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from scikit-learn) (3.6.0)\nRequirement already satisfied: sklearn-compat<0.2,>=0.1.5 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from imbalanced-learn) (0.1.5)\nRequirement already satisfied: contourpy>=1.0.1 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from matplotlib) (1.3.2)\nRequirement already satisfied: cycler>=0.10 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from matplotlib) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from matplotlib) (4.61.1)\nRequirement already satisfied: kiwisolver>=1.3.1 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from matplotlib) (1.4.9)\nRequirement already satisfied: packaging>=20.0 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from matplotlib) (25.0)\nRequirement already satisfied: pillow>=8 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from matplotlib) (12.1.0)\nRequirement already satisfied: pyparsing>=3 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from matplotlib) (3.3.1)\nRequirement already satisfied: mlflow-skinny==3.8.1 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from mlflow) (3.8.1)\nRequirement already satisfied: mlflow-tracing==3.8.1 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from mlflow) (3.8.1)\nRequirement already satisfied: Flask-CORS<7 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from mlflow) (6.0.2)\nRequirement already satisfied: Flask<4 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from mlflow) (3.1.2)\nRequirement already satisfied: alembic!=1.10.0,<2 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from mlflow) (1.17.2)\nRequirement already satisfied: cryptography<47,>=43.0.0 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from mlflow) (45.0.5)\nRequirement already satisfied: docker<8,>=4.0.0 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from mlflow) (7.1.0)\nRequirement already satisfied: graphene<4 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from mlflow) (3.4.3)\nRequirement already satisfied: gunicorn<24 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from mlflow) (23.0.0)\nRequirement already satisfied: huey<3,>=2.5.0 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from mlflow) (2.6.0)\nRequirement already satisfied: pyarrow<23,>=4.0.0 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from mlflow) (20.0.0)\nRequirement already satisfied: sqlalchemy<3,>=1.4.0 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from mlflow) (2.0.45)\nRequirement already satisfied: cachetools<7,>=5.0.0 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from mlflow-skinny==3.8.1->mlflow) (5.5.2)\nRequirement already satisfied: click<9,>=7.0 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from mlflow-skinny==3.8.1->mlflow) (8.2.1)\nRequirement already satisfied: cloudpickle<4 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from mlflow-skinny==3.8.1->mlflow) (2.2.1)\nRequirement already satisfied: databricks-sdk<1,>=0.20.0 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from mlflow-skinny==3.8.1->mlflow) (0.77.0)\nRequirement already satisfied: fastapi<1 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from mlflow-skinny==3.8.1->mlflow) (0.128.0)\nRequirement already satisfied: gitpython<4,>=3.1.9 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from mlflow-skinny==3.8.1->mlflow) (3.1.46)\nRequirement already satisfied: importlib_metadata!=4.7.0,<9,>=3.7.0 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from mlflow-skinny==3.8.1->mlflow) (8.7.0)\nRequirement already satisfied: opentelemetry-api<3,>=1.9.0 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from mlflow-skinny==3.8.1->mlflow) (1.35.0)\nRequirement already satisfied: opentelemetry-proto<3,>=1.9.0 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from mlflow-skinny==3.8.1->mlflow) (1.35.0)\nRequirement already satisfied: opentelemetry-sdk<3,>=1.9.0 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from mlflow-skinny==3.8.1->mlflow) (1.35.0)\nRequirement already satisfied: protobuf<7,>=3.12.0 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from mlflow-skinny==3.8.1->mlflow) (6.31.1)\nRequirement already satisfied: pydantic<3,>=2.0.0 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from mlflow-skinny==3.8.1->mlflow) (2.11.7)\nRequirement already satisfied: python-dotenv<2,>=0.19.0 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from mlflow-skinny==3.8.1->mlflow) (1.2.1)\nRequirement already satisfied: pyyaml<7,>=5.1 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from mlflow-skinny==3.8.1->mlflow) (6.0.2)\nRequirement already satisfied: requests<3,>=2.17.3 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from mlflow-skinny==3.8.1->mlflow) (2.32.4)\nRequirement already satisfied: sqlparse<1,>=0.4.0 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from mlflow-skinny==3.8.1->mlflow) (0.5.5)\nRequirement already satisfied: typing-extensions<5,>=4.0.0 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from mlflow-skinny==3.8.1->mlflow) (4.14.1)\nRequirement already satisfied: uvicorn<1 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from mlflow-skinny==3.8.1->mlflow) (0.40.0)\nRequirement already satisfied: Mako in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from alembic!=1.10.0,<2->mlflow) (1.3.10)\nRequirement already satisfied: tomli in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from alembic!=1.10.0,<2->mlflow) (2.2.1)\nRequirement already satisfied: cffi>=1.14 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from cryptography<47,>=43.0.0->mlflow) (1.15.0)\nRequirement already satisfied: google-auth~=2.0 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from databricks-sdk<1,>=0.20.0->mlflow-skinny==3.8.1->mlflow) (2.40.3)\nRequirement already satisfied: urllib3>=1.26.0 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from docker<8,>=4.0.0->mlflow) (2.5.0)\nRequirement already satisfied: starlette<0.51.0,>=0.40.0 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from fastapi<1->mlflow-skinny==3.8.1->mlflow) (0.50.0)\nRequirement already satisfied: annotated-doc>=0.0.2 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from fastapi<1->mlflow-skinny==3.8.1->mlflow) (0.0.4)\nRequirement already satisfied: blinker>=1.9.0 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from Flask<4->mlflow) (1.9.0)\nRequirement already satisfied: itsdangerous>=2.2.0 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from Flask<4->mlflow) (2.2.0)\nRequirement already satisfied: jinja2>=3.1.2 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from Flask<4->mlflow) (3.1.6)\nRequirement already satisfied: markupsafe>=2.1.1 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from Flask<4->mlflow) (2.1.1)\nRequirement already satisfied: werkzeug>=3.1.0 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from Flask<4->mlflow) (3.1.3)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from gitpython<4,>=3.1.9->mlflow-skinny==3.8.1->mlflow) (4.0.12)\nRequirement already satisfied: smmap<6,>=3.0.1 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow-skinny==3.8.1->mlflow) (5.0.2)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.8.1->mlflow) (0.4.2)\nRequirement already satisfied: rsa<5,>=3.1.4 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.8.1->mlflow) (4.9.1)\nRequirement already satisfied: graphql-core<3.3,>=3.1 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from graphene<4->mlflow) (3.2.7)\nRequirement already satisfied: graphql-relay<3.3,>=3.1 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from graphene<4->mlflow) (3.2.0)\nRequirement already satisfied: zipp>=3.20 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from importlib_metadata!=4.7.0,<9,>=3.7.0->mlflow-skinny==3.8.1->mlflow) (3.23.0)\nRequirement already satisfied: opentelemetry-semantic-conventions==0.56b0 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from opentelemetry-sdk<3,>=1.9.0->mlflow-skinny==3.8.1->mlflow) (0.56b0)\nRequirement already satisfied: annotated-types>=0.6.0 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from pydantic<3,>=2.0.0->mlflow-skinny==3.8.1->mlflow) (0.7.0)\nRequirement already satisfied: pydantic-core==2.33.2 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from pydantic<3,>=2.0.0->mlflow-skinny==3.8.1->mlflow) (2.33.2)\nRequirement already satisfied: typing-inspection>=0.4.0 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from pydantic<3,>=2.0.0->mlflow-skinny==3.8.1->mlflow) (0.4.1)\nRequirement already satisfied: six>=1.5 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\nRequirement already satisfied: charset_normalizer<4,>=2 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from requests<3,>=2.17.3->mlflow-skinny==3.8.1->mlflow) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from requests<3,>=2.17.3->mlflow-skinny==3.8.1->mlflow) (3.10)\nRequirement already satisfied: certifi>=2017.4.17 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from requests<3,>=2.17.3->mlflow-skinny==3.8.1->mlflow) (2025.7.9)\nRequirement already satisfied: pyasn1>=0.1.3 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from rsa<5,>=3.1.4->google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.8.1->mlflow) (0.6.1)\nRequirement already satisfied: greenlet>=1 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from sqlalchemy<3,>=1.4.0->mlflow) (3.3.0)\nRequirement already satisfied: anyio<5,>=3.6.2 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from starlette<0.51.0,>=0.40.0->fastapi<1->mlflow-skinny==3.8.1->mlflow) (3.7.1)\nRequirement already satisfied: sniffio>=1.1 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from anyio<5,>=3.6.2->starlette<0.51.0,>=0.40.0->fastapi<1->mlflow-skinny==3.8.1->mlflow) (1.3.1)\nRequirement already satisfied: exceptiongroup in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from anyio<5,>=3.6.2->starlette<0.51.0,>=0.40.0->fastapi<1->mlflow-skinny==3.8.1->mlflow) (1.3.0)\nRequirement already satisfied: h11>=0.8 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from uvicorn<1->mlflow-skinny==3.8.1->mlflow) (0.16.0)\nRequirement already satisfied: nvidia-nccl-cu12 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from xgboost) (2.28.9)\nRequirement already satisfied: backports.tempfile in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from azureml-core) (1.0)\nRequirement already satisfied: pathspec<1.0.0 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from azureml-core) (0.12.1)\nRequirement already satisfied: msal<2.0.0,>=1.15.0 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from azureml-core) (1.32.3)\nRequirement already satisfied: msal-extensions<=2.0.0,>=0.3.0 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from azureml-core) (1.3.1)\nRequirement already satisfied: knack<0.13.0 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from azureml-core) (0.12.0)\nRequirement already satisfied: azure-core<2.0.0 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from azureml-core) (1.35.0)\nRequirement already satisfied: pkginfo in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from azureml-core) (1.12.1.2)\nRequirement already satisfied: argcomplete<4 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from azureml-core) (3.6.2)\nRequirement already satisfied: humanfriendly<11.0,>=4.7 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from azureml-core) (10.0)\nRequirement already satisfied: paramiko<4.0.0,>=2.0.8 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from azureml-core) (3.5.1)\nRequirement already satisfied: azure-mgmt-resource<=24.0.0,>=15.0.0 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from azureml-core) (24.0.0)\nRequirement already satisfied: azure-mgmt-containerregistry<14,>=8.2.0 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from azureml-core) (13.0.0)\nRequirement already satisfied: azure-mgmt-storage<=23.0.0,>=16.0.0 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from azureml-core) (23.0.0)\nRequirement already satisfied: azure-mgmt-keyvault<12.0.0,>=0.40.0 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from azureml-core) (11.0.0)\nRequirement already satisfied: azure-mgmt-authorization<5,>=0.40.0 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from azureml-core) (4.0.0)\nRequirement already satisfied: azure-mgmt-network<=29.0.0 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from azureml-core) (29.0.0)\nRequirement already satisfied: azure-graphrbac<1.0.0,>=0.40.0 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from azureml-core) (0.61.2)\nRequirement already satisfied: azure-common<2.0.0,>=1.1.12 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from azureml-core) (1.1.28)\nRequirement already satisfied: msrest<=0.7.1,>=0.5.1 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from azureml-core) (0.7.1)\nRequirement already satisfied: msrestazure<=0.7,>=0.4.33 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from azureml-core) (0.6.4.post1)\nRequirement already satisfied: ndg-httpsclient<=0.5.1 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from azureml-core) (0.5.1)\nRequirement already satisfied: SecretStorage<4.0.0 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from azureml-core) (3.3.3)\nRequirement already satisfied: jsonpickle<5.0.0 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from azureml-core) (4.1.1)\nRequirement already satisfied: contextlib2<22.0.0 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from azureml-core) (21.6.0)\nRequirement already satisfied: PyJWT<3.0.0 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from azureml-core) (2.10.1)\nRequirement already satisfied: adal<=1.2.7,>=1.2.0 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from azureml-core) (1.2.7)\nRequirement already satisfied: pyopenssl<26.0.0 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from azureml-core) (25.1.0)\nRequirement already satisfied: jmespath<2.0.0 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from azureml-core) (1.0.1)\nRequirement already satisfied: isodate<1.0.0,>=0.6.1 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from azure-mgmt-authorization<5,>=0.40.0->azureml-core) (0.7.2)\nRequirement already satisfied: azure-mgmt-core<2.0.0,>=1.3.2 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from azure-mgmt-authorization<5,>=0.40.0->azureml-core) (1.6.0)\nRequirement already satisfied: pygments in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from knack<0.13.0->azureml-core) (2.19.2)\nRequirement already satisfied: tabulate in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from knack<0.13.0->azureml-core) (0.9.0)\nRequirement already satisfied: requests-oauthlib>=0.5.0 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from msrest<=0.7.1,>=0.5.1->azureml-core) (2.0.0)\nRequirement already satisfied: bcrypt>=3.2 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from paramiko<4.0.0,>=2.0.8->azureml-core) (4.3.0)\nRequirement already satisfied: pynacl>=1.5 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from paramiko<4.0.0,>=2.0.8->azureml-core) (1.5.0)\nRequirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from requests[socks]<3.0.0,>=2.19.1->azureml-core) (1.7.1)\nRequirement already satisfied: jeepney>=0.6 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from SecretStorage<4.0.0->azureml-core) (0.9.0)\nRequirement already satisfied: pycparser in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from cffi>=1.14->cryptography<47,>=43.0.0->mlflow) (2.22)\nRequirement already satisfied: oauthlib>=3.0.0 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from requests-oauthlib>=0.5.0->msrest<=0.7.1,>=0.5.1->azureml-core) (3.3.1)\nRequirement already satisfied: backports.weakref in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from backports.tempfile->azureml-core) (1.0.post1)\nNote: you may need to restart the kernel to use updated packages.\n"
        }
      ],
      "execution_count": 47,
      "metadata": {
        "gather": {
          "logged": 1767736457801
        },
        "jupyter": {
          "outputs_hidden": false
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from datetime import datetime\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Azure ML\n",
        "from azureml.core import Workspace, Experiment, Run\n",
        "from azureml.core.model import Model\n",
        "\n",
        "# Machine Learning\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.metrics import (\n",
        "    classification_report, confusion_matrix, \n",
        "    roc_auc_score, roc_curve, precision_recall_curve,\n",
        "    f1_score, precision_score, recall_score, accuracy_score\n",
        ")\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "\n",
        "# Algorithmes avanc√©s\n",
        "import xgboost as xgb\n",
        "import lightgbm as lgb\n",
        "\n",
        "# MLflow\n",
        "import mlflow\n",
        "import mlflow.sklearn\n",
        "import mlflow.xgboost\n",
        "import mlflow.lightgbm\n",
        "\n",
        "import joblib\n",
        "\n",
        "print(\"‚úÖ Biblioth√®ques import√©es avec succ√®s\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "‚úÖ Biblioth√®ques import√©es avec succ√®s\n"
        }
      ],
      "execution_count": 48,
      "metadata": {
        "gather": {
          "logged": 1767736462579
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Connexion Azure ML"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Connexion au workspace\n",
        "try:\n",
        "    ws = Workspace.from_config()\n",
        "    print(f\"‚úÖ Connect√© au workspace: {ws.name}\")\n",
        "except:\n",
        "    ws = Workspace(\n",
        "        subscription_id='<VOTRE_SUBSCRIPTION_ID>',\n",
        "        resource_group='<VOTRE_RESOURCE_GROUP>',\n",
        "        workspace_name='<VOTRE_WORKSPACE_NAME>'\n",
        "    )\n",
        "    print(f\"‚úÖ Connect√© au workspace: {ws.name}\")\n",
        "\n",
        "# Cr√©er l'exp√©rience principale\n",
        "experiment_name = 'fraud-detection-model-comparison'\n",
        "experiment = Experiment(workspace=ws, name=experiment_name)\n",
        "print(f\"‚úÖ Exp√©rience cr√©√©e: {experiment_name}\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1767711638907
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Chargement et Pr√©paration des Donn√©es"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "pip install azureml-dataset-runtime --upgrade"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1767711624139
        },
        "jupyter": {
          "outputs_hidden": false
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Charger les donn√©es\n",
        "from azureml.core import Workspace, Dataset, Datastore\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "\n",
        "# Configuration du style\n",
        "sns.set_style(\"whitegrid\")\n",
        "plt.rcParams['figure.figsize'] = (15, 5)\n",
        "\n",
        "datastore = Datastore.get(ws, datastore_name='workspaceblobstore')\n",
        "\n",
        "dataset = Dataset.Tabular.from_delimited_files(\n",
        "    path=[(datastore, 'fraud_dataset.csv')]\n",
        ")\n",
        "\n",
        "df = dataset.to_pandas_dataframe()\n",
        "print(f\"‚úÖ Donn√©es charg√©es: {df.shape[0]:,} lignes, {df.shape[1]} colonnes\")\n",
        "\n",
        "# Calculer les statistiques\n",
        "class_counts = df['isFraud'].value_counts()\n",
        "fraud_rate = df['isFraud'].mean() * 100\n",
        "\n",
        "print(f\"\\nTaux de fraude: {fraud_rate:.4f}%\")\n",
        "\n",
        "# Cr√©er une figure avec 3 sous-graphiques\n",
        "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
        "\n",
        "# 1. Graphique en barres\n",
        "axes[0].bar(['Non-Fraude', 'Fraude'], \n",
        "            [class_counts[False], class_counts[True]], \n",
        "            color=['#2ecc71', '#e74c3c'],\n",
        "            alpha=0.8,\n",
        "            edgecolor='black')\n",
        "axes[0].set_ylabel('Nombre de transactions', fontsize=12, fontweight='bold')\n",
        "axes[0].set_title('Distribution des Classes', fontsize=14, fontweight='bold')\n",
        "axes[0].set_ylim(0, max(class_counts) * 1.1)\n",
        "\n",
        "# Ajouter les valeurs sur les barres\n",
        "for i, (label, count) in enumerate(zip(['Non-Fraude', 'Fraude'], \n",
        "                                         [class_counts[False], class_counts[True]])):\n",
        "    axes[0].text(i, count, f'{count:,}', \n",
        "                ha='center', va='bottom', fontweight='bold', fontsize=11)\n",
        "\n",
        "# 2. Camembert (Pie chart)\n",
        "colors = ['#2ecc71', '#e74c3c']\n",
        "explode = (0, 0.1)  # \"exploser\" la tranche de fraude pour la mettre en √©vidence\n",
        "\n",
        "axes[1].pie([class_counts[False], class_counts[True]], \n",
        "           labels=['Non-Fraude', 'Fraude'],\n",
        "           autopct='%1.2f%%',\n",
        "           startangle=90,\n",
        "           colors=colors,\n",
        "           explode=explode,\n",
        "           shadow=True,\n",
        "           textprops={'fontsize': 11, 'fontweight': 'bold'})\n",
        "axes[1].set_title('Proportion des Classes', fontsize=14, fontweight='bold')\n",
        "\n",
        "# 3. Graphique en barres logarithmique pour mieux voir la diff√©rence\n",
        "axes[2].bar(['Non-Fraude', 'Fraude'], \n",
        "            [class_counts[False], class_counts[True]], \n",
        "            color=['#2ecc71', '#e74c3c'],\n",
        "            alpha=0.8,\n",
        "            edgecolor='black')\n",
        "axes[2].set_yscale('log')\n",
        "axes[2].set_ylabel('Nombre de transactions (√©chelle log)', fontsize=12, fontweight='bold')\n",
        "axes[2].set_title('Distribution (√âchelle Logarithmique)', fontsize=14, fontweight='bold')\n",
        "\n",
        "# Ajouter les valeurs\n",
        "for i, (label, count) in enumerate(zip(['Non-Fraude', 'Fraude'], \n",
        "                                         [class_counts[False], class_counts[True]])):\n",
        "    axes[2].text(i, count, f'{count:,}', \n",
        "                ha='center', va='bottom', fontweight='bold', fontsize=11)\n",
        "\n",
        "# Ajouter un titre g√©n√©ral\n",
        "fig.suptitle(f' Analyse de la Distribution des Classes - Taux de Fraude: {fraud_rate:.4f}%', \n",
        "             fontsize=16, fontweight='bold', y=1.02)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('fraud_distribution.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "# Afficher aussi un r√©sum√© sous forme de tableau\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"üìä R√âSUM√â DE LA DISTRIBUTION\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "summary_df = pd.DataFrame({\n",
        "    'Classe': ['Non-Fraude (False)', 'Fraude (True)'],\n",
        "    'Nombre': [f\"{class_counts[False]:,}\", f\"{class_counts[True]:,}\"],\n",
        "    'Pourcentage': [f\"{(class_counts[False]/len(df))*100:.2f}%\", \n",
        "                    f\"{(class_counts[True]/len(df))*100:.2f}%\"]\n",
        "})\n",
        "\n",
        "print(summary_df.to_string(index=False))\n",
        "print(\"=\"*50)\n",
        "\n",
        "# Afficher les premi√®res lignes\n",
        "df.head()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1767727414183
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Charger les donn√©es\n",
        "from azureml.core import Workspace, Dataset, Datastore\n",
        "\n",
        "datastore = Datastore.get(ws, datastore_name='workspaceblobstore')\n",
        "\n",
        "dataset = Dataset.Tabular.from_delimited_files(\n",
        "    path=[(datastore, 'fraud_dataset.csv')]\n",
        ")\n",
        "\n",
        "df = dataset.to_pandas_dataframe()\n",
        "print(f\"‚úÖ Donn√©es charg√©es: {df.shape[0]:,} lignes, {df.shape[1]} colonnes\")\n",
        "print(f\"\\nüìä Distribution des classes:\")\n",
        "print(df['isFraud'].value_counts())\n",
        "print(f\"\\nTaux de fraude: {df['isFraud'].mean()*100:.4f}%\")\n",
        "df.head()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1767711653658
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"üîß Feature Engineering en cours...\")\n",
        "\n",
        "# One-hot encoding\n",
        "df = pd.get_dummies(df, columns=['type'], prefix='type', drop_first=False)\n",
        "\n",
        "# S√©curit√© : √©viter divisions dangereuses\n",
        "EPS = 1e-6\n",
        "\n",
        "df['balanceChange_orig'] = df['oldbalanceOrg'] - df['newbalanceOrig']\n",
        "df['balanceChange_dest'] = df['newbalanceDest'] - df['oldbalanceDest']\n",
        "\n",
        "df['amountToBalanceRatio_orig'] = df['amount'] / (df['oldbalanceOrg'] + EPS)\n",
        "\n",
        "df['isOriginEmpty'] = (df['oldbalanceOrg'] == 0).astype(int)\n",
        "df['isDestEmpty'] = (df['oldbalanceDest'] == 0).astype(int)\n",
        "\n",
        "df['errorBalanceOrig'] = df['balanceChange_orig'] - df['amount']\n",
        "df['errorBalanceDest'] = df['balanceChange_dest'] - df['amount']\n",
        "\n",
        "# Nettoyage final : remplacer inf par NaN\n",
        "df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "\n",
        "# Supprimer colonnes non n√©cessaires\n",
        "df = df.drop(columns=['nameOrig', 'nameDest', 'isFlaggedFraud'], errors='ignore')\n",
        "\n",
        "print(f\"‚úÖ Feature Engineering compl√©t√© - {df.shape[1]} features\")\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1767711673277
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# S√©paration X/y\n",
        "X = df.drop('isFraud', axis=1)\n",
        "y = df['isFraud']\n",
        "feature_names = X.columns.tolist()\n",
        "\n",
        "print(f\"Features (X): {X.shape}\")\n",
        "print(f\"Target (y): {y.shape}\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1767711673705
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split Train/Test\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "print(f\"Train set: {X_train.shape[0]:,} transactions\")\n",
        "print(f\"Test set: {X_test.shape[0]:,} transactions\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1767711676674
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "imputer = SimpleImputer(strategy=\"median\")\n",
        "\n",
        "X_train_imputed = imputer.fit_transform(X_train)\n",
        "X_test_imputed = imputer.transform(X_test)\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1767711698368
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalisation apr√®s imputation\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train_imputed)\n",
        "X_test_scaled  = scaler.transform(X_test_imputed)\n",
        "\n",
        "print(\"‚úÖ Donn√©es normalis√©es\")\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1767711699640
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "over = SMOTE(sampling_strategy=0.5, random_state=42)\n",
        "under = RandomUnderSampler(sampling_strategy=0.8, random_state=42)\n",
        "\n",
        "X_train_balanced, y_train_balanced = over.fit_resample(X_train_scaled, y_train)\n",
        "X_train_balanced, y_train_balanced = under.fit_resample(\n",
        "    X_train_balanced, y_train_balanced\n",
        ")\n",
        "\n",
        "print(\"‚úÖ R√©√©quilibrage r√©ussi\")\n",
        "print(pd.Series(y_train_balanced).value_counts())\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1767711703621
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Fonction Utilitaire pour l'Experiment Tracking"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "def train_and_evaluate_model(model, model_name, X_train, y_train, X_test, y_test, run):\n",
        "    \"\"\"\n",
        "    Entra√Æne un mod√®le et log toutes les m√©triques dans Azure ML\n",
        "    \n",
        "    Args:\n",
        "        model: Le mod√®le √† entra√Æner\n",
        "        model_name: Nom du mod√®le pour le tracking\n",
        "        X_train, y_train: Donn√©es d'entra√Ænement\n",
        "        X_test, y_test: Donn√©es de test\n",
        "        run: Azure ML Run object\n",
        "    \n",
        "    Returns:\n",
        "        dict: M√©triques de performance\n",
        "    \"\"\"\n",
        "    print(f\"\\n{'='*70}\")\n",
        "    print(f\"üöÄ Entra√Ænement: {model_name}\")\n",
        "    print(f\"{'='*70}\")\n",
        "    \n",
        "    # Entra√Ænement\n",
        "    start_time = datetime.now()\n",
        "    model.fit(X_train, y_train)\n",
        "    training_time = (datetime.now() - start_time).total_seconds()\n",
        "    \n",
        "    # Pr√©dictions\n",
        "    y_pred = model.predict(X_test)\n",
        "    y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
        "    \n",
        "    # Calcul des m√©triques\n",
        "    metrics = {\n",
        "        'model_name': model_name,\n",
        "        'accuracy': accuracy_score(y_test, y_pred),\n",
        "        'precision': precision_score(y_test, y_pred),\n",
        "        'recall': recall_score(y_test, y_pred),\n",
        "        'f1_score': f1_score(y_test, y_pred),\n",
        "        'roc_auc': roc_auc_score(y_test, y_pred_proba),\n",
        "        'training_time_seconds': training_time\n",
        "    }\n",
        "    \n",
        "    # Log des m√©triques dans Azure ML\n",
        "    run.log('model_name', model_name)\n",
        "    run.log('accuracy', metrics['accuracy'])\n",
        "    run.log('precision', metrics['precision'])\n",
        "    run.log('recall', metrics['recall'])\n",
        "    run.log('f1_score', metrics['f1_score'])\n",
        "    run.log('roc_auc', metrics['roc_auc'])\n",
        "    run.log('training_time_seconds', training_time)\n",
        "    \n",
        "    # Affichage des r√©sultats\n",
        "    print(f\"\\nüìä R√©sultats:\")\n",
        "    print(f\"  Accuracy:  {metrics['accuracy']:.4f}\")\n",
        "    print(f\"  Precision: {metrics['precision']:.4f}\")\n",
        "    print(f\"  Recall:    {metrics['recall']:.4f}\")\n",
        "    print(f\"  F1-Score:  {metrics['f1_score']:.4f}\")\n",
        "    print(f\"  ROC-AUC:   {metrics['roc_auc']:.4f}\")\n",
        "    print(f\"  Temps:     {training_time:.2f}s\")\n",
        "    \n",
        "    # Matrice de confusion\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "                xticklabels=['L√©gal', 'Fraude'],\n",
        "                yticklabels=['L√©gal', 'Fraude'])\n",
        "    plt.title(f'Matrice de Confusion - {model_name}', fontsize=14, fontweight='bold')\n",
        "    plt.ylabel('Vraie Classe')\n",
        "    plt.xlabel('Classe Pr√©dite')\n",
        "    plt.tight_layout()\n",
        "    \n",
        "    # Sauvegarder et logger l'image\n",
        "    img_path = f'confusion_matrix_{model_name.replace(\" \", \"_\")}.png'\n",
        "    plt.savefig(img_path, dpi=300, bbox_inches='tight')\n",
        "    run.log_image(f'confusion_matrix_{model_name}', plot=plt)\n",
        "    plt.close()\n",
        "    \n",
        "    return metrics, model, y_pred_proba\n",
        "\n",
        "print(\"‚úÖ Fonction d'√©valuation cr√©√©e\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1767711704058
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Experiment Tracking - Entra√Ænement de Plusieurs Mod√®les\n",
        "\n",
        "Nous allons entra√Æner et comparer 5 versions diff√©rentes de mod√®les"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Workspace, Experiment, Run\n",
        "\n",
        "\n",
        "# D√©finir un nom fixe pour l'experiment\n",
        "experiment_name = \"Fraud-Detection-Experiment\" \n",
        "experiment = Experiment(workspace=ws, name=experiment_name)\n",
        "\n",
        "# D√©marrer le run parent\n",
        "parent_run = experiment.start_logging()\n",
        "\n",
        "# Afficher info\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"üß™ D√âBUT DE L'EXPERIMENT TRACKING\")\n",
        "print(\"=\"*70)\n",
        "print(f\"Exp√©rience: {experiment.name}\")  \n",
        "print(f\"Run ID: {parent_run.id}\")\n",
        "\n",
        "# 5Ô∏è‚É£ Dictionnaires pour stocker les r√©sultats et mod√®les\n",
        "all_results = []\n",
        "all_models = {}\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1767714439941
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Mod√®le 1: Random Forest (Baseline)"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Child run 1\n",
        "child_run_1 = parent_run.child_run(name=\"RF_Baseline\")\n",
        "\n",
        "model_1 = RandomForestClassifier(\n",
        "    n_estimators=50,\n",
        "    max_depth=10,\n",
        "    random_state=42,\n",
        "    n_jobs=-1,\n",
        "    class_weight='balanced'\n",
        ")\n",
        "\n",
        "# Log des hyperparam√®tres\n",
        "child_run_1.log('n_estimators', 50)\n",
        "child_run_1.log('max_depth', 10)\n",
        "child_run_1.log('algorithm', 'RandomForest')\n",
        "\n",
        "metrics_1, trained_model_1, proba_1 = train_and_evaluate_model(\n",
        "    model_1, 'Random Forest (Baseline)', \n",
        "    X_train_balanced, y_train_balanced, \n",
        "    X_test_scaled, y_test,\n",
        "    child_run_1\n",
        ")\n",
        "\n",
        "all_results.append(metrics_1)\n",
        "all_models['RF_Baseline'] = trained_model_1\n",
        "child_run_1.complete()\n",
        "print(\"‚úÖ Mod√®le 1 compl√©t√©\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1767714668106
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Mod√®le 2: Random Forest (Optimis√©)"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Child run 2\n",
        "child_run_2 = parent_run.child_run(name=\"RF_Optimized\")\n",
        "\n",
        "model_2 = RandomForestClassifier(\n",
        "    n_estimators=100,\n",
        "    max_depth=20,\n",
        "    min_samples_split=10,\n",
        "    min_samples_leaf=5,\n",
        "    max_features='sqrt',\n",
        "    random_state=42,\n",
        "    n_jobs=-1,\n",
        "    class_weight='balanced'\n",
        ")\n",
        "\n",
        "child_run_2.log('n_estimators', 100)\n",
        "child_run_2.log('max_depth', 20)\n",
        "child_run_2.log('min_samples_split', 10)\n",
        "child_run_2.log('min_samples_leaf', 5)\n",
        "child_run_2.log('algorithm', 'RandomForest')\n",
        "\n",
        "metrics_2, trained_model_2, proba_2 = train_and_evaluate_model(\n",
        "    model_2, 'Random Forest (Optimis√©)', \n",
        "    X_train_balanced, y_train_balanced, \n",
        "    X_test_scaled, y_test,\n",
        "    child_run_2\n",
        ")\n",
        "\n",
        "all_results.append(metrics_2)\n",
        "all_models['RF_Optimized'] = trained_model_2\n",
        "child_run_2.complete()\n",
        "print(\"‚úÖ Mod√®le 2 compl√©t√©\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1767715134942
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Mod√®le 3: XGBoost"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Child run 3\n",
        "child_run_3 = parent_run.child_run(name=\"XGBoost\")\n",
        "\n",
        "# Calculer le scale_pos_weight pour g√©rer le d√©s√©quilibre\n",
        "scale_pos_weight = (y_train_balanced == 0).sum() / (y_train_balanced == 1).sum()\n",
        "\n",
        "model_3 = xgb.XGBClassifier(\n",
        "    n_estimators=100,\n",
        "    max_depth=6,\n",
        "    learning_rate=0.1,\n",
        "    scale_pos_weight=scale_pos_weight,\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "child_run_3.log('n_estimators', 100)\n",
        "child_run_3.log('max_depth', 6)\n",
        "child_run_3.log('learning_rate', 0.1)\n",
        "child_run_3.log('scale_pos_weight', scale_pos_weight)\n",
        "child_run_3.log('algorithm', 'XGBoost')\n",
        "\n",
        "metrics_3, trained_model_3, proba_3 = train_and_evaluate_model(\n",
        "    model_3, 'XGBoost', \n",
        "    X_train_balanced, y_train_balanced, \n",
        "    X_test_scaled, y_test,\n",
        "    child_run_3\n",
        ")\n",
        "\n",
        "all_results.append(metrics_3)\n",
        "all_models['XGBoost'] = trained_model_3\n",
        "child_run_3.complete()\n",
        "print(\"‚úÖ Mod√®le 3 compl√©t√©\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1767715170389
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Mod√®le 4: LightGBM"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Child run 4\n",
        "child_run_4 = parent_run.child_run(name=\"LightGBM\")\n",
        "\n",
        "model_4 = lgb.LGBMClassifier(\n",
        "    n_estimators=100,\n",
        "    max_depth=6,\n",
        "    learning_rate=0.1,\n",
        "    num_leaves=31,\n",
        "    random_state=42,\n",
        "    n_jobs=-1,\n",
        "    class_weight='balanced'\n",
        ")\n",
        "\n",
        "child_run_4.log('n_estimators', 100)\n",
        "child_run_4.log('max_depth', 6)\n",
        "child_run_4.log('learning_rate', 0.1)\n",
        "child_run_4.log('num_leaves', 31)\n",
        "child_run_4.log('algorithm', 'LightGBM')\n",
        "\n",
        "metrics_4, trained_model_4, proba_4 = train_and_evaluate_model(\n",
        "    model_4, 'LightGBM', \n",
        "    X_train_balanced, y_train_balanced, \n",
        "    X_test_scaled, y_test,\n",
        "    child_run_4\n",
        ")\n",
        "\n",
        "all_results.append(metrics_4)\n",
        "all_models['LightGBM'] = trained_model_4\n",
        "child_run_4.complete()\n",
        "print(\"‚úÖ Mod√®le 4 compl√©t√©\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1767715215212
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Comparaison des R√©sultats de Tous les Mod√®les"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Cr√©er un DataFrame de comparaison\n",
        "comparison_df = pd.DataFrame(all_results)\n",
        "comparison_df = comparison_df.sort_values('f1_score', ascending=False)\n",
        "\n",
        "print(\"\\n\" + \"=\"*100)\n",
        "print(\"üìä TABLEAU COMPARATIF DES MOD√àLES\")\n",
        "print(\"=\"*100)\n",
        "print(comparison_df.to_string(index=False))\n",
        "print(\"=\"*100)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1767715215616
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Sauvegarder le tableau de comparaison\n",
        "comparison_df.to_csv('model_comparison.csv', index=False)\n",
        "parent_run.upload_file('model_comparison.csv', 'model_comparison.csv')\n",
        "print(\"‚úÖ Tableau de comparaison sauvegard√©\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1767715215963
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualisation comparative - Graphique en barres\n",
        "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
        "fig.suptitle('Comparaison des Performances des Mod√®les', fontsize=16, fontweight='bold')\n",
        "\n",
        "metrics_to_plot = ['accuracy', 'precision', 'recall', 'f1_score', 'roc_auc', 'training_time_seconds']\n",
        "metric_names = ['Accuracy', 'Precision', 'Recall', 'F1-Score', 'ROC-AUC', 'Temps (s)']\n",
        "\n",
        "for idx, (metric, name) in enumerate(zip(metrics_to_plot, metric_names)):\n",
        "    row = idx // 3\n",
        "    col = idx % 3\n",
        "    ax = axes[row, col]\n",
        "    \n",
        "    # Extraire les valeurs\n",
        "    models = comparison_df['model_name'].values\n",
        "    values = comparison_df[metric].values\n",
        "    \n",
        "    # Cr√©er le graphique\n",
        "    colors = plt.cm.viridis(np.linspace(0.3, 0.9, len(models)))\n",
        "    bars = ax.bar(range(len(models)), values, color=colors, edgecolor='black', linewidth=1.5)\n",
        "    \n",
        "    # Ajouter les valeurs sur les barres\n",
        "    for i, (bar, val) in enumerate(zip(bars, values)):\n",
        "        height = bar.get_height()\n",
        "        ax.text(bar.get_x() + bar.get_width()/2., height,\n",
        "                f'{val:.4f}' if metric != 'training_time_seconds' else f'{val:.2f}',\n",
        "                ha='center', va='bottom', fontsize=9, fontweight='bold')\n",
        "    \n",
        "    ax.set_xticks(range(len(models)))\n",
        "    ax.set_xticklabels(models, rotation=45, ha='right', fontsize=9)\n",
        "    ax.set_ylabel(name, fontsize=11, fontweight='bold')\n",
        "    ax.set_title(name, fontsize=12, fontweight='bold')\n",
        "    ax.grid(axis='y', alpha=0.3, linestyle='--')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('model_comparison_bars.png', dpi=300, bbox_inches='tight')\n",
        "parent_run.log_image('model_comparison_bars', plot=plt)\n",
        "plt.show()\n",
        "\n",
        "print(\"‚úÖ Graphiques de comparaison cr√©√©s\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1767713806372
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. S√©lection et Enregistrement du Meilleur Mod√®le"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Identifier le meilleur mod√®le bas√© sur le F1-Score\n",
        "best_model_row = comparison_df.iloc[0]\n",
        "best_model_name = best_model_row['model_name']\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"üèÜ MEILLEUR MOD√àLE S√âLECTIONN√â\")\n",
        "print(\"=\"*70)\n",
        "print(f\"\\nMod√®le: {best_model_name}\")\n",
        "print(f\"\\nPerformances:\")\n",
        "print(f\"  - Accuracy:  {best_model_row['accuracy']:.4f}\")\n",
        "print(f\"  - Precision: {best_model_row['precision']:.4f}\")\n",
        "print(f\"  - Recall:    {best_model_row['recall']:.4f}\")\n",
        "print(f\"  - F1-Score:  {best_model_row['f1_score']:.4f}\")\n",
        "print(f\"  - ROC-AUC:   {best_model_row['roc_auc']:.4f}\")\n",
        "print(\"=\"*70)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1767713948618
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# R√©cup√©rer le meilleur mod√®le\n",
        "model_key = best_model_name.replace(' ', '_').replace('(', '').replace(')', '')\n",
        "if 'Baseline' in best_model_name:\n",
        "    best_model = all_models['RF_Baseline']\n",
        "elif 'Optimis√©' in best_model_name:\n",
        "    best_model = all_models['RF_Optimized']\n",
        "elif 'Gradient' in best_model_name:\n",
        "    best_model = all_models['GradientBoosting']\n",
        "elif 'XGBoost' in best_model_name:\n",
        "    best_model = all_models['XGBoost']\n",
        "elif 'LightGBM' in best_model_name:\n",
        "    best_model = all_models['LightGBM']\n",
        "\n",
        "# Sauvegarder le meilleur mod√®le\n",
        "best_model_filename = 'best_fraud_detection_model.pkl'\n",
        "joblib.dump(best_model, best_model_filename)\n",
        "joblib.dump(scaler, 'scaler.pkl')\n",
        "\n",
        "print(f\"‚úÖ Meilleur mod√®le sauvegard√©: {best_model_filename}\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1767713951593
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Enregistrer dans Azure ML\n",
        "parent_run.upload_file(name='outputs/' + best_model_filename, path_or_stream=best_model_filename)\n",
        "parent_run.upload_file(name='outputs/scaler.pkl', path_or_stream='scaler.pkl')\n",
        "\n",
        "# Enregistrer comme mod√®le Azure ML\n",
        "registered_model = parent_run.register_model(\n",
        "    model_name='fraud-detection-best',\n",
        "    model_path='outputs/' + best_model_filename,\n",
        "    description=f'Best fraud detection model: {best_model_name}',\n",
        "    tags={\n",
        "        'algorithm': best_model_name,\n",
        "        'accuracy': f\"{best_model_row['accuracy']:.4f}\",\n",
        "        'f1_score': f\"{best_model_row['f1_score']:.4f}\",\n",
        "        'roc_auc': f\"{best_model_row['roc_auc']:.4f}\",\n",
        "        'experiment': experiment_name\n",
        "    }\n",
        ")\n",
        "\n",
        "print(f\"‚úÖ Mod√®le enregistr√© dans Azure ML: {registered_model.name}, Version: {registered_model.version}\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1767713974234
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Enregistrer tous les mod√®les individuellement\n",
        "print(\"\\nüì¶ Enregistrement de tous les mod√®les...\")\n",
        "\n",
        "for idx, row in comparison_df.iterrows():\n",
        "    model_name = row['model_name']\n",
        "    model_key = model_name.replace(' ', '_').replace('(', '').replace(')', '')\n",
        "    \n",
        "    if 'Baseline' in model_name:\n",
        "        model = all_models['RF_Baseline']\n",
        "    elif 'Optimis√©' in model_name:\n",
        "        model = all_models['RF_Optimized']\n",
        "    elif 'Gradient' in model_name:\n",
        "        model = all_models['GradientBoosting']\n",
        "    elif 'XGBoost' in model_name:\n",
        "        model = all_models['XGBoost']\n",
        "    elif 'LightGBM' in model_name:\n",
        "        model = all_models['LightGBM']\n",
        "    \n",
        "    filename = f\"model_{model_key}.pkl\"\n",
        "    joblib.dump(model, filename)\n",
        "    print(f\"  ‚úì {model_name} sauvegard√©\")\n",
        "\n",
        "print(\"\\n‚úÖ Tous les mod√®les ont √©t√© enregistr√©s\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1767713826858
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Terminer le run parent\n",
        "parent_run.complete()\n",
        "print(\"\\n‚úÖ Exp√©rience Azure ML termin√©e\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1767713832995
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8. Export pour Power BI"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Export du tableau de comparaison pour Power BI\n",
        "comparison_df.to_csv('model_comparison_powerbi.csv', index=False)\n",
        "\n",
        "# Cr√©er un r√©sum√© d√©taill√©\n",
        "summary_df = comparison_df.copy()\n",
        "summary_df['rank'] = range(1, len(summary_df) + 1)\n",
        "summary_df = summary_df[[\n",
        "    'rank', 'model_name', 'accuracy', 'precision', 'recall', \n",
        "    'f1_score', 'roc_auc', 'training_time_seconds'\n",
        "]]\n",
        "\n",
        "summary_df.to_csv('models_detailed_summary.csv', index=False)\n",
        "\n",
        "print(\"‚úÖ Fichiers export√©s pour Power BI:\")\n",
        "print(\"   - model_comparison_powerbi.csv\")\n",
        "print(\"   - models_detailed_summary.csv\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1767650513556
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.18",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      },
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "kernel_info": {
      "name": "python3"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}